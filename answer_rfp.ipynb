{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc56327-7958-46eb-af66-def2b07b4e0c",
   "metadata": {},
   "source": [
    "### Prototype for an RFX Answering AI Assistant\n",
    "\n",
    "* read question from an **xls** file\n",
    "* answers based on a **KNOWLEDGE BASE**: a set of documents saved in a Vector Store\n",
    "* manage the **history** of questions\n",
    "* provides the list of references\n",
    "* it is possible to change prompt, to improve answers\n",
    "* if a reranker is used provides relevance scores for refs\n",
    "* can use LLMLingua as prompt compressor\n",
    "\n",
    "Additional info:\n",
    "* Using the Vector Store configured in config.py\n",
    "* if you want to improve changing prompts, change in **oracle_chat_prompts.py**. Maybe you need to change only the second prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa69836-3e79-4033-959e-1323fcbe1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# to read, write xls\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# my code to simplify use of LangChain\n",
    "# this function will return a contextualized RAG chain\n",
    "# using chat_history\n",
    "\n",
    "# changed to use the forked for rfx\n",
    "from factory_rfx import build_rag_chain\n",
    "\n",
    "from utils import print_configuration, get_console_logger, remove_path_from_ref\n",
    "\n",
    "# config (some config are read by get_rag_chain())\n",
    "from config_rfx import DO_STREAMING, ADD_RERANKER, ADD_REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe004f-95dc-4e1c-bc6b-d1961908d9f8",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* If you don't have a LangSmith account, set in config.py ENABLE_TRACING = **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2518af3a-0a73-42b9-89c7-c25e80a23dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for input/output\n",
    "\n",
    "# the input file is here...\n",
    "INPUT_DIR = Path(\".\")\n",
    "# output file in this directory\n",
    "OUTPUT_DIR = Path(\".\")\n",
    "\n",
    "# Input: we take the questions from this file\n",
    "QUERY_FILE = \"rfp01.xlsx\"\n",
    "\n",
    "# the name of the column with all questions\n",
    "QUESTION_COL_NAME = \"Question\"\n",
    "\n",
    "# full path of questions file\n",
    "QUERY_PATH_NAME = INPUT_DIR / QUERY_FILE\n",
    "\n",
    "# we write results to this file\n",
    "OUTPUT_FILE_NAME = \"answers01.xlsx\"\n",
    "OUTPUT_PATH_NAME = OUTPUT_DIR / OUTPUT_FILE_NAME\n",
    "\n",
    "logger = get_console_logger()\n",
    "\n",
    "# Num. of questions to answer (only to limit time in regression test)\n",
    "# put a very high value to answer ALL\n",
    "NUM_Q_TO_ANSWER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49b0049-05c9-42c7-8ae8-500b3e58b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that streaming has been disabled\n",
    "# this NB must be run with False\n",
    "assert DO_STREAMING is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8931f1-4301-4652-928d-b4bd20aca2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "def format_metadata(metadata):\n",
    "    \"\"\"\n",
    "    input: metadata is a dict\n",
    "    \"\"\"\n",
    "    # remove path from source\n",
    "    metadata[\"source\"] = remove_path_from_ref(metadata[\"source\"])\n",
    "\n",
    "    # we can add the relevance score only if there is a reranker\n",
    "    MAX_DEC_DIGITS = 4\n",
    "\n",
    "    # reduce num of digits in the relevance score\n",
    "    if ADD_RERANKER:\n",
    "        metadata[\"relevance_score\"] = round(metadata[\"relevance_score\"], MAX_DEC_DIGITS)\n",
    "\n",
    "        result_string = f\"Source: {metadata['source']} pag.: {metadata['page']}, score: {metadata['relevance_score']}\"\n",
    "    else:\n",
    "        # no reranker, remove the score\n",
    "        # with LLMLingua no relevance score\n",
    "        result_string = f\"Source: {metadata['source']} pag.: {metadata['page']}\"\n",
    "\n",
    "    return result_string\n",
    "\n",
    "\n",
    "def print_references(response_ai_msg):\n",
    "    \"\"\"\n",
    "    format refs lines and remove duplicates (due to chunking)\n",
    "\n",
    "    added error handling (source not found?)\n",
    "    \"\"\"\n",
    "    list_bookname_page = []\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"References:\")\n",
    "\n",
    "    try:\n",
    "        for doc in response_ai_msg[\"context\"]:\n",
    "            book_name_page = doc.metadata[\"source\"] + str(doc.metadata[\"page\"])\n",
    "\n",
    "            if book_name_page not in list_bookname_page:\n",
    "                print(format_metadata(doc.metadata))\n",
    "\n",
    "                # register it\n",
    "                list_bookname_page.append(book_name_page)\n",
    "\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        # go over\n",
    "        print(\"......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41a03-61ce-4531-ab80-bad48f1bd16e",
   "metadata": {},
   "source": [
    "#### Read the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4755d13-5725-4734-b045-455297156ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 19:26:31,733 - There are 12 questions...\n",
      "2024-05-26 19:26:31,734 - \n",
      "2024-05-26 19:26:31,734 - First 5 questions:\n",
      "2024-05-26 19:26:31,734 - ['What is the last release for Oracle Database?', 'Is it a long term release support?', 'What functionalities Oracle DB provides for High Availability?', 'What functionalities Oracle DB provides for JSON Support?', 'List new functionalities regarding JSON']\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_excel(QUERY_PATH_NAME)\n",
    "\n",
    "questions = list(input_df[QUESTION_COL_NAME].values)\n",
    "\n",
    "# a look at the first five questions\n",
    "\n",
    "logger.info(f\"There are {len(questions)} questions...\")\n",
    "logger.info(\"\")\n",
    "logger.info(\"First 5 questions:\")\n",
    "logger.info(questions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba547d-48aa-4445-8b4f-1cbb57d70c8c",
   "metadata": {},
   "source": [
    "#### Init the RAG chain and Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a114ac44-d46d-4c97-82ee-acf33ed647d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 19:26:33,492 - --------------------------------------------------\n",
      "2024-05-26 19:26:33,493 - Configuration used:\n",
      "2024-05-26 19:26:33,494 - \n",
      "2024-05-26 19:26:33,495 -  Embedding model type: OCI\n",
      "2024-05-26 19:26:33,496 -  Using cohere.embed-multilingual-v3.0 for Embeddings...\n",
      "2024-05-26 19:26:33,497 -  Added Cohere Reranker...\n",
      "2024-05-26 19:26:33,498 -  Using rerank-multilingual-v3.0 as reranker...\n",
      "2024-05-26 19:26:33,499 -  Using OPENSEARCH as Vector Store...\n",
      "2024-05-26 19:26:33,500 -  Retrieval parameters:\n",
      "2024-05-26 19:26:33,500 -     TOP_K: 8\n",
      "2024-05-26 19:26:33,502 -     TOP_N: 4\n",
      "2024-05-26 19:26:33,503 -  Using COHERE as Generative Model type...\n",
      "2024-05-26 19:26:33,504 -  Using command-r for LLM...\n",
      "2024-05-26 19:26:33,504 - \n",
      "2024-05-26 19:26:33,505 -  Enabled Observability with LangSmith...\n",
      "2024-05-26 19:26:33,505 - --------------------------------------------------\n",
      "2024-05-26 19:26:33,506 - \n",
      "2024-05-26 19:26:33,655 - Adding a reranker...\n"
     ]
    }
   ],
   "source": [
    "# here we will put input and outputs to give context\n",
    "# to reset chat, simply empty the list\n",
    "chat_history = []\n",
    "\n",
    "# here we will save answers, to create the output file\n",
    "answers = []\n",
    "\n",
    "# we create the RAG chain with LangChain\n",
    "rag_chain = build_rag_chain(None, None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1cd67-8adb-4e63-a12c-a60e1a6753e7",
   "metadata": {},
   "source": [
    "#### Answer all the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e467999-225e-4555-9ef2-3cc0908d7ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "\n",
      "Question n. 1: What is the last release for Oracle Database?:\n",
      "\n",
      "According to the provided information, the latest release of Oracle Database is Oracle Database 23ai, released on May 13, 2024. It is documented in the Oracle Database New Features Release 23ai.\n",
      "\n",
      "References:\n",
      "Source: oracle-database-23ai-new-features-guide.pdf pag.: 0, score: 0.8818\n",
      "Source: oracle-database-23c-new-features-guide.pdf pag.: 0, score: 0.861\n",
      "Source: oracle-database-23ai-new-features-guide.pdf pag.: 3, score: 0.7576\n",
      "Source: database-concepts.pdf pag.: 337, score: 0.0003\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Question n. 2: Is it a long term release support?:\n",
      "\n",
      "Yes, according to the information I have access to, Oracle Database 23ai and Oracle Database 23c are both described as long-term support releases. They are the current most up-to-date versions of Oracle Database, building upon the extensive features of Oracle Database 21c and introducing over 300 new capabilities and enhancements.\n",
      "\n",
      "References:\n",
      "Source: oracle-database-23ai-new-features-guide.pdf pag.: 3, score: 1.0\n",
      "Source: oracle-database-23c-new-features-guide.pdf pag.: 64, score: 1.0\n",
      "Source: oracle-database-23c-new-features-guide.pdf pag.: 11, score: 1.0\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Question n. 3: What functionalities Oracle DB provides for High Availability?:\n",
      "\n",
      "Oracle Database provides several functionalities and features to ensure high availability and minimize downtime. Here are some of the key functionalities related to high availability:\n",
      "\n",
      "1. Oracle Data Guard: This is a key feature that ensures high availability and disaster recovery. It creates and maintains one or more standby databases that replicate the primary database. In case of a failure, the standby database can take over with minimal data loss. Oracle Data Guard offers different protection modes, including Maximum Availability and Maximum Performance, to balance data protection and performance.\n",
      "\n",
      "2. Fast Start Failover (FSFO): FSFO enables quick and automated failover to a standby database in the event of a primary database failure. It reduces the time needed to recover and minimizes data loss.\n",
      "\n",
      "3. Multi-Instance Redo Apply (MIRA): MIRA is a feature of Oracle Data Guard that enables scalable redo apply performance across multiple instances of an Oracle RAC database. It improves the efficiency of failover and reduces the time required to return to operation (RTO).\n",
      "\n",
      "4. Compare and Verify: Oracle Database provides tools like DBMS_DBCOMP package to compare primary and standby database blocks, helping to identify and resolve lost writes efficiently. This ensures data integrity and aids in troubleshooting.\n",
      "\n",
      "5. Active Data Guard: This feature allows reporting and some workload offloading to a standby database. It improves the utilization of standby databases and enables zero planned downtime when upgrading the database.\n",
      "\n",
      "6. Oracle GoldenGate: Oracle GoldenGate is a flexible logical replication solution that supports active-active high availability. It enables real-time data integration and replication between heterogeneous databases and provides conflict resolution in active-active configurations.\n",
      "\n",
      "7. Oracle Real Application Clusters (RAC): RAC allows multiple instances to access and control a single database. It provides high availability by tolerating instance failures and load balancing.\n",
      "\n",
      "8. Automatic Storage Management (ASM): ASM provides simplified storage management and high availability through mirroring and online rebalancing. It helps protect data from storage failures.\n",
      "\n",
      "9. Oracle Enterprise Manager: This is a comprehensive management tool that enables proactive monitoring, management, and tuning of Oracle databases. It includes features like the Diagnostic Tool and SQL Tuning Advisor to optimize performance and facilitate administration.\n",
      "\n",
      "10. Flashback Technologies: Oracle Database offers various flashback technologies, such as Flashback Database, Flashback Query, and Flashback Drop, which allow you to revert to previous database states, query historical data, or recover dropped objects.\n",
      "\n",
      "These are just some of the key functionalities Oracle Database provides for high availability. Oracle also offers additional features and options within its stack, like Oracle Cloud Infrastructure, to further enhance availability and streamline disaster recovery processes.\n",
      "\n",
      "References:\n",
      "Source: high-availability-23c.pdf pag.: 40, score: 1.0\n",
      "Source: high-availability-23c.pdf pag.: 78, score: 1.0\n",
      "Source: high-availability-23c.pdf pag.: 35, score: 1.0\n",
      "Source: high-availability-23c.pdf pag.: 37, score: 1.0\n",
      "\n",
      "CPU times: user 327 ms, sys: 21.4 ms, total: 348 ms\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loop all over the questions, call RAG chain, save answer\n",
    "for i, question in enumerate(questions):\n",
    "    if i > NUM_Q_TO_ANSWER:\n",
    "        # exit\n",
    "        break\n",
    "\n",
    "    # print the header of the section\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(f\"Question n. {i+1}: {question}:\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "\n",
    "        # to give context for the answers we need to save questions\n",
    "        # and answers in the chat history as Messages, with the right roles\n",
    "        chat_history.append(HumanMessage(content=question))\n",
    "\n",
    "        # the invocation to the RAG chain, with the history\n",
    "\n",
    "        # can add instructions this way\n",
    "        # question += \" Rispondi in italiano.\"\n",
    "\n",
    "        input_msg = {\n",
    "            \"input\": question,\n",
    "            \"chat_history\": chat_history,\n",
    "        }\n",
    "\n",
    "        # we need to check if we have setup streaming mode,\n",
    "        # for the right invocation\n",
    "        if DO_STREAMING:\n",
    "            ai_msg = rag_chain.stream(input_msg)\n",
    "        else:\n",
    "            ai_msg = rag_chain.invoke(input_msg)\n",
    "\n",
    "        # extract only the answer\n",
    "        answer = ai_msg[\"answer\"]\n",
    "\n",
    "        # print the answer\n",
    "        print(answer)\n",
    "\n",
    "        # print the link to refs (chunks of text used as context for answers)\n",
    "        if ADD_REFERENCES:\n",
    "            print_references(ai_msg)\n",
    "\n",
    "        # save the answer\n",
    "        answers.append(answer)\n",
    "\n",
    "        # save in the msg history\n",
    "        chat_history.append(AIMessage(content=answer))\n",
    "    except Exception as e:\n",
    "        # got an error, try to continue\n",
    "        print(\"\")\n",
    "        print(\"Got unexpected error.. try to continue...\")\n",
    "        print(\"\")\n",
    "\n",
    "        answers.append(\"Not available...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530c0a1-84bb-4792-a57d-781e14578013",
   "metadata": {},
   "source": [
    "#### Save the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffc3a2-d3f4-4896-91ce-f670f368d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas, maybe will find a better way\n",
    "dict_out = {\"Question\": questions, \"Answer\": answers}\n",
    "\n",
    "output_df = pd.DataFrame(dict_out)\n",
    "\n",
    "logger.info(f\"Writing answers to: {OUTPUT_PATH_NAME}\")\n",
    "\n",
    "output_df.to_excel(OUTPUT_PATH_NAME, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491530f-08d0-46fb-89e9-33c19ed3b1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
